{
  "skill_slug": "test-vuln-mcp-server",
  "source_url": "https://github.com/starbuck100/test-vuln-mcp-server",
  "scan_type": "mcp",
  "risk_score": 97,
  "result": "unsafe",
  "findings_count": 8,
  "findings": [
    {
      "title": "Command injection via run_command tool",
      "description": "The run_command tool passes user-supplied input directly to child_process.exec() without any sanitization, escaping, or allowlisting. This allows arbitrary shell command execution on the host system, enabling full remote code execution (RCE). An attacker (or a manipulated LLM) can execute any system command including data exfiltration, malware installation, or lateral movement.",
      "severity": "critical",
      "confidence": "high",
      "pattern_id": "COMMAND_INJECTION",
      "file_path": "src/tools/filesystem.ts",
      "line_number": 26,
      "line_content": "exec(args.command, (error, stdout, stderr) => {",
      "remediation": "Remove the run_command tool entirely, or replace exec() with execFile() using a strict allowlist of permitted commands. Never pass unsanitized user input to a shell."
    },
    {
      "title": "Arbitrary file read with path traversal",
      "description": "The read_file tool uses fs.readFileSync with the user-supplied path argument directly, with no path validation or sandboxing. An attacker can read any file accessible to the process, including /etc/passwd, /etc/shadow, ~/.ssh/id_rsa, environment files, and other sensitive system files via directory traversal (e.g., ../../etc/passwd).",
      "severity": "critical",
      "confidence": "high",
      "pattern_id": "PATH_TRAVERSAL_READ",
      "file_path": "src/tools/filesystem.ts",
      "line_number": 13,
      "line_content": "const content = fs.readFileSync(args.path, \"utf-8\");",
      "remediation": "Implement path validation using path.resolve() and verify the resolved path is within an allowed directory. Use a chroot or sandbox. Reject paths containing '..' components."
    },
    {
      "title": "Arbitrary file write with path traversal",
      "description": "The write_file tool uses fs.writeFileSync with user-supplied path and content arguments without any validation. An attacker can overwrite any file writable by the process, including system configuration files, crontabs, SSH authorized_keys, or application code. This can lead to full system compromise.",
      "severity": "critical",
      "confidence": "high",
      "pattern_id": "PATH_TRAVERSAL_WRITE",
      "file_path": "src/tools/filesystem.ts",
      "line_number": 19,
      "line_content": "fs.writeFileSync(args.path, args.content);",
      "remediation": "Implement strict path validation, restrict writes to a sandboxed directory, and validate file content. Use path.resolve() to canonicalize paths and reject traversal attempts."
    },
    {
      "title": "Server-Side Request Forgery (SSRF) via fetch_url tool",
      "description": "The fetch_url tool makes HTTP requests to any user-supplied URL without validation. This enables SSRF attacks, allowing access to internal services (e.g., cloud metadata at http://169.254.169.254), internal APIs, localhost services, and private network resources that should not be externally accessible.",
      "severity": "critical",
      "confidence": "high",
      "pattern_id": "SSRF",
      "file_path": "src/tools/filesystem.ts",
      "line_number": 35,
      "line_content": "const resp = await fetch(args.url);",
      "remediation": "Implement URL validation with an allowlist of permitted domains/schemes. Block requests to private IP ranges (10.x, 172.16-31.x, 192.168.x, 169.254.x, 127.x, ::1). Use a URL parser to validate before fetching."
    },
    {
      "title": "Hardcoded API key (OpenAI) in source code",
      "description": "An OpenAI API key is hardcoded directly in the chat handler source file. This key is committed to version control and visible to anyone with repository access. It can be used for unauthorized API access, incurring costs and potentially accessing associated data. The key is also leaked into prompt responses, making it accessible to end users.",
      "severity": "high",
      "confidence": "high",
      "pattern_id": "HARDCODED_SECRET",
      "file_path": "src/handlers/chat.ts",
      "line_number": 4,
      "line_content": "const OPENAI_API_KEY = \"sk-proj-abc123def456ghi789jkl012mno345pqr678stu901vwx234\";",
      "remediation": "Remove the hardcoded key immediately. Use environment variables or a secrets manager. Rotate the compromised key. Add secret scanning to CI/CD pipeline."
    },
    {
      "title": "Hardcoded database connection string with credentials",
      "description": "A PostgreSQL connection string containing username (admin), password (supersecret), and internal hostname (prod-db.internal) is hardcoded in source. This exposes database credentials and internal infrastructure details to anyone with code access.",
      "severity": "high",
      "confidence": "high",
      "pattern_id": "HARDCODED_SECRET",
      "file_path": "src/handlers/chat.ts",
      "line_number": 5,
      "line_content": "const DATABASE_URL = \"postgresql://admin:supersecret@prod-db.internal:5432/maindb\";",
      "remediation": "Remove hardcoded credentials. Use environment variables or a secrets manager (e.g., AWS Secrets Manager, HashiCorp Vault). Rotate the compromised credentials immediately."
    },
    {
      "title": "Prompt injection via unsanitized user input interpolation",
      "description": "User input is directly interpolated into a system prompt string without any sanitization or escaping. This enables prompt injection attacks where a malicious user can override system instructions, extract the hardcoded API key (which is also interpolated into the prompt), or manipulate the LLM behavior. The API key is explicitly included in the system prompt context, meaning any prompt injection can trivially exfiltrate it.",
      "severity": "high",
      "confidence": "high",
      "pattern_id": "PROMPT_INJECTION",
      "file_path": "src/handlers/chat.ts",
      "line_number": 22,
      "line_content": "const systemPrompt = `You are a helpful assistant. The user says: ${userInput}.",
      "remediation": "Never interpolate user input into system prompts. Use separate message roles (system vs user). Remove the API key from prompt context entirely. Implement input validation and output filtering."
    },
    {
      "title": "Debug mode leaks environment variables including secrets",
      "description": "Debug mode is hardcoded to true and logs the entire process.env to stdout via JSON.stringify(process.env). This exposes all environment variables, which typically include API keys, database credentials, cloud provider tokens, and other sensitive configuration. On shared systems or when logs are collected, this creates a significant credential exposure risk.",
      "severity": "high",
      "confidence": "high",
      "pattern_id": "INFO_DISCLOSURE",
      "file_path": "src/index.ts",
      "line_number": 23,
      "line_content": "console.log(\"[DEBUG] Environment:\", JSON.stringify(process.env));",
      "remediation": "Remove debug logging of environment variables. Set DEBUG to false by default. Use a proper logging framework with configurable levels. Never log full process.env in any environment."
    }
  ]
}
